# iTransformer Decoder-Only 模型配置文件
# 版本: v0.1
# 日期: 20251212

metadata:
  version: "v0.1"
  date: "20251212"
  description: "iTransformer Decoder-Only配置"

model:
  name: "itransformer_decoder"
  
  # 输入输出维度（会自动根据实际数据调整，这里的值只是初始值）
  input_features: 40  # 特征数量（会自动检测并更新，无需手动修改）
  seq_len: 100        # 输入序列长度（会自动检测并更新）
  output_dim: 1        # 输出维度（预测收盘价）
  
  # 模型架构参数
  d_model: 512         # 模型隐藏维度
  n_layers: 6          # Decoder层数
  n_heads: 4           # 注意力头数（需能整除 seq_len；已调整为4以适配 seq_len=100）
  d_ff: 2048           # Feed-Forward网络隐藏维度
  dropout: 0.1         # Dropout比率
  activation: "gelu"   # 激活函数: "gelu" 或 "relu"
  
  # Decoder层配置
  decoder:
    use_causal_mask: False    # 是否使用因果掩码（Causal Mask）
    norm_type: "pre"         # 归一化类型: "pre" (Pre-Norm) 或 "post" (Post-Norm)
    attention_dropout: 0.1   # 注意力层Dropout比率
    ff_dropout: 0.1          # Feed-Forward层Dropout比率
    use_bias: true            # 是否在Linear层使用bias
  
  # 输入ResNet模块配置（在Decoder之前）
  # 结构：实际特征数 -> 128 -> 256 -> 512（每个模块5层）
  # 注意：第一个模块的输入维度会自动调整为实际特征数量，无需手动修改
  input_resnet:
    enabled: true            # 是否启用输入ResNet模块
    dims: [128, 256, 512]   # ResNet模块的输出维度列表（每个模块5层）
    dropout: 0.1            # Dropout比率
    activation: "gelu"      # 激活函数
    use_bias: true          # 是否使用bias
  
  # 时间维度聚合模块配置（在Decoder之后，输出ResNet之前）
  # 结构：seq_len(100) -> 50（ResNet，5层，有残差）-> 25 -> 5 -> 1（全连接，3层，无残差，无dropout）
  # 用于学习如何聚合所有时间步的信息，而不是硬编码取最后一个时间步
  time_aggregation_resnet:
    enabled: true            # 是否启用时间维度聚合模块
    dims: [50]              # ResNet模块的输出维度（100 -> 50，使用ResNet）
    dropout: 0.1            # Dropout比率（仅用于ResNet部分）
    activation: "gelu"      # 激活函数
    use_bias: true          # 是否使用bias
    # 注意：50 -> 1的部分使用3层全连接（50->25->5->1），无残差，无dropout
  
  # 输出ResNet模块配置（在时间维度聚合之后）
  # 结构：512 -> 256 -> 128 -> 64（每个模块5层）
  output_resnet:
    enabled: true            # 是否启用输出ResNet模块
    dims: [256, 128, 64]    # ResNet模块的输出维度列表（每个模块5层）
    dropout: 0.1            # Dropout比率
    activation: "gelu"      # 激活函数
    use_bias: true          # 是否使用bias
  
  # 最终输出层参数（从输出ResNet的最后一层维度64降到1）
  # 结构：64 -> 32 -> 16 -> 1（3层全连接，前2层有激活无dropout，最后1层无激活）
  final_output:
    output_dim: 1           # 输出维度（预测收盘价）
    activation: "gelu"       # 激活函数（用于前2层）
    use_bias: true           # 是否使用bias
    # 注意：所有层都无dropout，最后1层无激活函数

