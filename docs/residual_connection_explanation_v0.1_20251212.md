# æ®‹å·®è¿æ¥ï¼ˆResidual Connectionï¼‰è¯¦è§£

## ğŸ”— æ®‹å·®è¿æ¥çš„å·¥ä½œåŸç†

### ä»£ç ä½ç½®

**æ–‡ä»¶**ï¼š`src/models/v0.1_20251212/itransformer_decoder.py`

**ç±»**ï¼š`ResidualFCBlock`ï¼ˆç¬¬38-128è¡Œï¼‰

### å…³é”®ä»£ç 

```python
def forward(self, x: torch.Tensor) -> torch.Tensor:
    residual = x  # ç¬¬111è¡Œï¼šä¿å­˜åŸå§‹è¾“å…¥
    
    # å¦‚æœè¾“å…¥è¾“å‡ºç»´åº¦ä¸åŒï¼Œéœ€è¦æŠ•å½±æ®‹å·®
    if self.residual_proj is not None:
        residual = self.residual_proj(residual)  # ç¬¬115è¡Œï¼šæŠ•å½±æ®‹å·®
    
    # é€šè¿‡æ‰€æœ‰å±‚
    out = x
    for linear, norm, dropout in zip(self.layers, self.norms, self.dropouts):
        out = linear(out)      # ç¬¬120è¡Œï¼šçº¿æ€§å˜æ¢
        out = norm(out)        # ç¬¬121è¡Œï¼šå½’ä¸€åŒ–
        out = self.activation(out)  # ç¬¬122è¡Œï¼šæ¿€æ´»
        out = dropout(out)     # ç¬¬123è¡Œï¼šDropout
    
    # æ®‹å·®è¿æ¥ï¼šåŸå§‹æ•°æ®åŠ åˆ°æœ€åä¸€å±‚çš„è¾“å‡º
    out = out + residual  # ç¬¬126è¡Œï¼šå…³é”®ï¼åŸå§‹è¾“å…¥åŠ åˆ°æœ€åä¸€å±‚è¾“å‡º
    
    return out
```

---

## ğŸ“Š æ®‹å·®è¿æ¥ç¤ºæ„å›¾

### 10å±‚æ®‹å·®ç½‘ç»œçš„ä¾‹å­

å‡è®¾é…ç½®ï¼š
```yaml
layers: 10
hidden_dims: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
```

**æ•°æ®æµ**ï¼š
```
è¾“å…¥ x (åŸå§‹æ•°æ®)
    â†“
ç¬¬1å±‚: Linear -> Norm -> Activation -> Dropout
    â†“
ç¬¬2å±‚: Linear -> Norm -> Activation -> Dropout
    â†“
...
    â†“
ç¬¬10å±‚: Linear -> Norm -> Activation -> Dropout
    â†“
è¾“å‡º = ç¬¬10å±‚è¾“å‡º + åŸå§‹è¾“å…¥ x
```

**å…³é”®ç‚¹**ï¼š
- âœ… åŸå§‹è¾“å…¥ `x` åœ¨ç¬¬111è¡Œè¢«ä¿å­˜ä¸º `residual`
- âœ… ç»è¿‡æ‰€æœ‰10å±‚å¤„ç†åï¼Œå¾—åˆ° `out`
- âœ… ç¬¬126è¡Œï¼š`out = out + residual`
- âœ… **åŸå§‹æ•°æ®åŠ åˆ°ç¬¬10å±‚çš„è¾“å‡º**

---

## ğŸ¯ ç»´åº¦åŒ¹é…è§„åˆ™

### æƒ…å†µ1ï¼šè¾“å…¥è¾“å‡ºç»´åº¦ç›¸åŒ

**ç¤ºä¾‹**ï¼š`40 -> 40 (2å±‚)`

```python
input_dim = 40
hidden_dims = [40, 40]  # æœ€åä¸€å±‚è¾“å‡º40ç»´
output_dim = 40

# æ®‹å·®è¿æ¥
residual = x  # (batch, 40)
out = ç»è¿‡2å±‚åçš„è¾“å‡º  # (batch, 40)
out = out + residual  # (batch, 40) + (batch, 40) = (batch, 40) âœ…
```

**ä¸éœ€è¦æŠ•å½±å±‚**ï¼š`residual_proj = None`

### æƒ…å†µ2ï¼šè¾“å…¥è¾“å‡ºç»´åº¦ä¸åŒ

**ç¤ºä¾‹**ï¼š`40 -> 128 (1å±‚)`

```python
input_dim = 40
hidden_dims = [128]  # æœ€åä¸€å±‚è¾“å‡º128ç»´
output_dim = 128

# æ®‹å·®è¿æ¥
residual = x  # (batch, 40)
# éœ€è¦æŠ•å½±ï¼š40 -> 128
residual = residual_proj(residual)  # (batch, 128)
out = ç»è¿‡1å±‚åçš„è¾“å‡º  # (batch, 128)
out = out + residual  # (batch, 128) + (batch, 128) = (batch, 128) âœ…
```

**éœ€è¦æŠ•å½±å±‚**ï¼š`residual_proj = Linear(40, 128)`

---

## âš ï¸ é…ç½®å†²çªé—®é¢˜

### é—®é¢˜ï¼š`input_features: 45` å’Œ `hidden_dims: [40, 40]` å†²çªå—ï¼Ÿ

**ç­”æ¡ˆ**ï¼šä¼šå†²çªï¼ä½†å·²ç»è‡ªåŠ¨ä¿®å¤ã€‚

**å†²çªåœºæ™¯**ï¼š
- é…ç½®æ–‡ä»¶ï¼š`input_features: 45`
- ç¬¬ä¸€ä¸ªæ¨¡å—ï¼š`hidden_dims: [40, 40]`
- å®é™…æ•°æ®ï¼š45ä¸ªç‰¹å¾

**ä¼šå‘ç”Ÿä»€ä¹ˆ**ï¼š
1. ç¨‹åºæ£€æµ‹åˆ°å®é™…ç‰¹å¾æ•°æ˜¯45
2. è‡ªåŠ¨è°ƒæ•´ç¬¬ä¸€ä¸ªæ¨¡å—ä¸ºï¼š`hidden_dims: [45, 45]`
3. æ¨¡å‹ä½¿ç”¨45ä½œä¸ºè¾“å…¥ç»´åº¦

**è‡ªåŠ¨è°ƒæ•´ä»£ç ä½ç½®**ï¼š`scripts/v0.1_20251212/train.py` ç¬¬292-302è¡Œ

---

## ğŸ”§ å¦‚ä½•æ­£ç¡®é…ç½®

### æ¨èåšæ³•

**æ–¹æ³•1ï¼šè®©ç¨‹åºè‡ªåŠ¨è°ƒæ•´ï¼ˆæ¨èï¼‰**
```yaml
input_features: 45  # è¿™ä¸ªå€¼ä¼šè¢«è‡ªåŠ¨æ›´æ–°ï¼Œå†™ä»€ä¹ˆéƒ½è¡Œ
input_resnet:
  modules:
    - name: "input_block_1"
      layers: 2
      hidden_dims: [40, 40]  # è¿™ä¸ªä¼šè¢«è‡ªåŠ¨è°ƒæ•´ä¸ºå®é™…ç‰¹å¾æ•°
```

**æ–¹æ³•2ï¼šæ‰‹åŠ¨è®¾ç½®ï¼ˆå¦‚æœä½ çŸ¥é“ç¡®åˆ‡çš„ç‰¹å¾æ•°ï¼‰**
```yaml
input_features: 45
input_resnet:
  modules:
    - name: "input_block_1"
      layers: 2
      hidden_dims: [45, 45]  # æ‰‹åŠ¨è®¾ç½®ä¸º45
```

---

## ğŸ“ æ€»ç»“

1. **æ®‹å·®è¿æ¥ä½ç½®**ï¼šç¬¬126è¡Œ `out = out + residual`
2. **åŸå§‹æ•°æ®åŠ åˆ°å“ªä¸€å±‚**ï¼šåŠ åˆ°**æœ€åä¸€å±‚**çš„è¾“å‡º
3. **10å±‚ç½‘ç»œ**ï¼šåŸå§‹æ•°æ®ä¼šåŠ åˆ°ç¬¬10å±‚çš„è¾“å‡º
4. **é…ç½®å†²çª**ï¼šå·²è‡ªåŠ¨å¤„ç†ï¼Œç¨‹åºä¼šè‡ªåŠ¨è°ƒæ•´ç¬¬ä¸€ä¸ªæ¨¡å—çš„ç»´åº¦

