"""ä¸œæ–¹è´¢å¯Œæ•°æ®æºæ¨¡å— v0.5 - æ¸¯è‚¡NOTICE_DATE APIè·å–ç‰ˆ

v0.5 æ–°å¢åŠŸèƒ½ï¼š
1. âœ… æ¸¯è‚¡NOTICE_DATE APIè·å–ï¼šä»ä¸œæ–¹è´¢å¯ŒAPIç›´æ¥è·å–çœŸå®çš„æŠ«éœ²æ—¥æœŸ
2. âœ… æ¸¯è‚¡æ—¥æœŸæ•°æ®å®Œæ•´æ€§ï¼šæ”¯æŒè·å–å†å²çœŸå®çš„è´¢æŠ¥æŠ«éœ²æ—¥æœŸ
3. âœ… å®Œå…¨å‘åå…¼å®¹ï¼šæ‰€æœ‰v0.4åŠŸèƒ½å®Œå…¨ä¿ç•™

v0.4 åŸºç¡€åŠŸèƒ½ï¼š
1. âœ… ç¾è‚¡è´¢åŠ¡æŒ‡æ ‡APIä¼˜åŒ–ï¼šä½¿ç”¨è‡ªå®šä¹‰å®ç°æ›¿ä»£akshareï¼Œç›´æ¥è°ƒç”¨ä¸œæ–¹è´¢å¯ŒAPI
2. âœ… æ”¯æŒä¸åŒä¼ä¸šç±»å‹ï¼šæ ¹æ®å…¬å¸ç±»å‹ï¼ˆä¸€èˆ¬ä¼ä¸š/é“¶è¡Œ/ä¿é™©ï¼‰è‡ªåŠ¨é€‰æ‹©å¯¹åº”APIæ¥å£
3. âœ… å®Œå…¨å‘åå…¼å®¹ï¼šæ‰€æœ‰å‡½æ•°ç­¾åä¿æŒä¸å˜ï¼Œä¸å½±å“ç°æœ‰ä»£ç 
4. âœ… ä¿æŒæ‰€æœ‰v0.3åŠŸèƒ½ï¼šå‘¨æœŸå‚æ•°ã€å®¹é”™å¤„ç†ç­‰åŠŸèƒ½å®Œå…¨ä¿ç•™

v0.3 åŸºç¡€åŠŸèƒ½ï¼š
1. âœ… æ¸¯è‚¡å‘¨æœŸå‚æ•°ï¼šæ”¯æŒ"å¹´åº¦"å’Œ"æŠ¥å‘ŠæœŸ"ä¸¤ç§å‘¨æœŸé€‰æ‹©
2. âœ… ç¾è‚¡å‘¨æœŸå‚æ•°ï¼šæ”¯æŒ"å¹´æŠ¥"ã€"å•å­£æŠ¥"ã€"ç´¯è®¡å­£æŠ¥"ä¸‰ç§å‘¨æœŸé€‰æ‹©
3. âœ… å‘åå…¼å®¹ï¼šæ‰€æœ‰æ–°å¢å‚æ•°éƒ½æœ‰é»˜è®¤å€¼ï¼Œä¸å½±å“ç°æœ‰ä»£ç 
4. âœ… ç»Ÿä¸€æ¥å£ï¼šAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡éƒ½å¯ä»¥é€šè¿‡å‚æ•°çµæ´»é€‰æ‹©æ•°æ®å‘¨æœŸ

v0.2 åŸºç¡€åŠŸèƒ½ï¼š
1. âœ… å®Œæ•´çš„å®¹é”™å¤„ç†ï¼šå•ä¸ªè¡¨æ ¼è·å–å¤±è´¥ä¸å½±å“å…¶ä»–è¡¨æ ¼
2. âœ… çŠ¶æ€è®°å½•ï¼šè¯¦ç»†è®°å½•æ¯ä¸ªè¡¨æ ¼çš„è·å–çŠ¶æ€ï¼ˆæˆåŠŸ/å¤±è´¥/åŸå› ï¼‰
3. âœ… æ•°æ®å®Œæ•´æ€§ï¼šå³ä½¿éƒ¨åˆ†æ•°æ®ç¼ºå¤±ï¼Œä¹Ÿè¿”å›å·²è·å–çš„æ•°æ®
4. âœ… é€‚ç”¨æ‰€æœ‰å¸‚åœºï¼šAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ç»Ÿä¸€å®¹é”™å¤„ç†

v0.1 åŸºç¡€åŠŸèƒ½ï¼š
1. Pivotå‰é‡å‘½åï¼šä¿ç•™åŒä¸€æŠ¥è¡¨å†…çš„æ‰€æœ‰é‡å¤æ•°æ®ï¼Œé¿å…æ•°æ®ä¸¢å¤±
2. å…¨å±€é‡å‘½åï¼šç»Ÿä¸€æ‰€æœ‰æŠ¥è¡¨åˆå¹¶åçš„åˆ—åï¼Œæ¶ˆé™¤åµŒå¥—åç¼€
3. ç»Ÿä¸€å¤„ç†ï¼šAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ä½¿ç”¨ç›¸åŒçš„å‘½åè§„åˆ™

æä¾›Aè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡çš„è´¢åŠ¡æ•°æ®å’Œè´¢åŠ¡æŒ‡æ ‡è·å–åŠŸèƒ½ã€‚

è¯¥æ¨¡å—é€šè¿‡akshareåº“ä»ä¸œæ–¹è´¢å¯Œç½‘è·å–è‚¡ç¥¨è´¢åŠ¡æ•°æ®ï¼ŒåŒ…æ‹¬ï¼š
- è´¢åŠ¡æ•°æ®ï¼šèµ„äº§è´Ÿå€ºè¡¨ã€åˆ©æ¶¦è¡¨ã€ç°é‡‘æµé‡è¡¨
- è´¢åŠ¡æŒ‡æ ‡ï¼šå„ç§è´¢åŠ¡åˆ†ææŒ‡æ ‡
- æ¸¯è‚¡æŠ«éœ²æ—¥æœŸï¼šçœŸå®çš„å†å²è´¢æŠ¥æŠ«éœ²æ—¥æœŸï¼ˆv0.5æ–°å¢ï¼‰
"""

import re
import functools
import akshare as ak
import pandas as pd
import requests
from datetime import datetime, timedelta
from providers.us_financial_analysis_indicator import stock_financial_us_analysis_indicator_em


# ==================== v0.5 æ–°å¢ï¼šæ¸¯è‚¡NOTICE_DATEè·å–å‡½æ•° ====================

def get_hk_financial_report_dates(stock_code):
    """
    ä»ä¸œæ–¹è´¢å¯ŒAPIè·å–æ¸¯è‚¡çœŸå®çš„è´¢æŠ¥æŠ«éœ²æ—¥æœŸï¼ˆv0.5æ–°å¢ï¼‰
    
    è¯¥å‡½æ•°ç›´æ¥è°ƒç”¨ä¸œæ–¹è´¢å¯ŒF10æ•°æ®æ¥å£ï¼Œè·å–æ¸¯è‚¡çš„é‡å¤§äº‹ä»¶æ•°æ®ï¼Œ
    ä»ä¸­æå–"æŠ¥è¡¨æŠ«éœ²"äº‹ä»¶çš„NOTICE_DATEï¼ˆå…¬å‘Šæ—¥æœŸï¼‰ï¼Œå¹¶åæ¨å¯¹åº”çš„REPORT_DATEï¼ˆè´¢æŠ¥æœŸï¼‰ã€‚
    
    Args:
        stock_code (str): æ¸¯è‚¡ä»£ç ï¼Œå¦‚ '00700'ï¼ˆä¸éœ€è¦.HKåç¼€ï¼‰
    
    Returns:
        pd.DataFrame or None: 
            - æˆåŠŸï¼šè¿”å›åŒ…å« [REPORT_DATE, NOTICE_DATE] ä¸¤åˆ—çš„DataFrame
            - å¤±è´¥ï¼šè¿”å› None
    
    ç¤ºä¾‹ï¼š
        >>> dates_df = get_hk_financial_report_dates('00700')
        >>> print(dates_df)
           REPORT_DATE  NOTICE_DATE
        0   2024-12-31   2025-03-20
        1   2024-09-30   2024-11-13
        2   2024-06-30   2024-08-14
    
    æ³¨æ„ï¼š
        - è¿”å›çš„REPORT_DATEæ˜¯æ ¹æ®NOTICE_DATEçš„æœˆä»½åæ¨çš„ï¼ˆéµå¾ªé¦™æ¸¯è´¢æŠ¥è§„åˆ™ï¼‰
        - 1-3æœˆå…¬å‘Š â†’ ä¸Šå¹´12-31æŠ¥è¡¨
        - 4-6æœˆå…¬å‘Š â†’ å½“å¹´03-31æŠ¥è¡¨
        - 7-9æœˆå…¬å‘Š â†’ å½“å¹´06-30æŠ¥è¡¨
        - 10-12æœˆå…¬å‘Š â†’ å½“å¹´09-30æŠ¥è¡¨
    """
    try:
        # æ„é€ APIè¯·æ±‚
        url = "https://datacenter.eastmoney.com/securities/api/data/get"
        params = {
            "type": "RPT_F10_HK_DETAIL",
            "params": f'{stock_code}.HK',
            "p": "1",
            "source": "F10",
            "client": "PC"
        }
        
        # å‘é€è¯·æ±‚
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        # æ£€æŸ¥è¿”å›æ•°æ®
        if 'data' not in data or not data['data']:
            print(f"  âš ï¸  æ¸¯è‚¡ {stock_code} APIè¿”å›ç©ºæ•°æ®")
            return None
        
        # å±•å¹³åµŒå¥—åˆ—è¡¨
        flat_data = [event for sublist in data['data'] for event in sublist]
        
        if not flat_data:
            print(f"  âš ï¸  æ¸¯è‚¡ {stock_code} æ— äº‹ä»¶æ•°æ®")
            return None
        
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(flat_data)
        
        # è¿‡æ»¤å‡º"æŠ¥è¡¨æŠ«éœ²"äº‹ä»¶
        if 'EVENT_TYPE' not in df.columns:
            print(f"  âš ï¸  æ¸¯è‚¡ {stock_code} æ•°æ®ä¸­æ— EVENT_TYPEå­—æ®µ")
            return None
        
        df = df[df['EVENT_TYPE'] == 'æŠ¥è¡¨æŠ«éœ²']
        
        if df.empty:
            print(f"  âš ï¸  æ¸¯è‚¡ {stock_code} æ— æŠ¥è¡¨æŠ«éœ²è®°å½•")
            return None
        
        # æ£€æŸ¥å¿…è¦çš„åˆ—
        if 'NOTICE_DATE' not in df.columns:
            print(f"  âš ï¸  æ¸¯è‚¡ {stock_code} æ•°æ®ä¸­æ— NOTICE_DATEå­—æ®µ")
            return None
        
        # å®šä¹‰æ—¥æœŸè½¬æ¢å‡½æ•°ï¼šæ ¹æ®å…¬å‘Šæ—¥æœŸåæ¨è´¢æŠ¥æœŸ
        def calculate_financial_date(announcement_date_str):
            """æ ¹æ®å…¬å‘Šæœˆä»½æ¨ç®—å¯¹åº”çš„è´¢æŠ¥æˆªæ­¢æ—¥æœŸ"""
            try:
                date = datetime.strptime(announcement_date_str, "%Y-%m-%d")
                year, month = date.year, date.month
                
                if month in [1, 2, 3]:
                    return f"{year - 1}-12-31"
                elif month in [4, 5, 6]:
                    return f"{year}-03-31"
                elif month in [7, 8, 9]:
                    return f"{year}-06-30"
                else:  # 10, 11, 12
                    return f"{year}-09-30"
            except:
                return None
        
        # è®¡ç®—è´¢æŠ¥æˆªæ­¢æ—¥æœŸ
        df['REPORT_DATE'] = df['NOTICE_DATE'].apply(calculate_financial_date)
        
        # ç­›é€‰æœ‰æ•ˆæ•°æ®
        result_df = df[['REPORT_DATE', 'NOTICE_DATE']].dropna()
        
        if result_df.empty:
            print(f"  âš ï¸  æ¸¯è‚¡ {stock_code} æ— æœ‰æ•ˆçš„æ—¥æœŸæ˜ å°„")
            return None
        
        # å»é‡ï¼ˆä¿ç•™ç¬¬ä¸€æ¡è®°å½•ï¼‰
        result_df = result_df.drop_duplicates(subset=['REPORT_DATE'], keep='first')
        
        print(f"  âœ“ æ¸¯è‚¡ {stock_code} APIè·å–æˆåŠŸï¼š{len(result_df)} æ¡æŠ«éœ²æ—¥æœŸ")
        
        return result_df.reset_index(drop=True)
        
    except requests.Timeout:
        print(f"  âœ— æ¸¯è‚¡ {stock_code} APIè¯·æ±‚è¶…æ—¶")
        return None
    except requests.RequestException as e:
        print(f"  âœ— æ¸¯è‚¡ {stock_code} APIè¯·æ±‚å¤±è´¥: {e}")
        return None
    except Exception as e:
        print(f"  âœ— æ¸¯è‚¡ {stock_code} NOTICE_DATEè·å–å¼‚å¸¸: {e}")
        return None


# ==================== è¾…åŠ©å‡½æ•°ï¼šé‡å‘½åå’Œå»é‡ ====================

def _rename_duplicates_before_pivot(df, date_col='REPORT_DATE', name_col='STD_ITEM_NAME'):
    """
    åœ¨pivotå‰å¯¹é‡å¤çš„(æ—¥æœŸ, é¡¹ç›®å)ç»„åˆæ·»åŠ åºå·åç¼€ï¼Œé¿å…æ•°æ®ä¸¢å¤±
    
    å¤„ç†é€»è¾‘ï¼š
    1. å¯¹æ¯ä¸ª(æ—¥æœŸ, é¡¹ç›®)ç»„åˆè®¡ç®—å‡ºç°æ¬¡æ•°
    2. ç¬¬1æ¬¡å‡ºç°ï¼šä¿æŒåŸå
    3. ç¬¬2æ¬¡å‡ºç°ï¼šæ·»åŠ  _1
    4. ç¬¬3æ¬¡å‡ºç°ï¼šæ·»åŠ  _2
    ... ä»¥æ­¤ç±»æ¨
    
    ç¤ºä¾‹ï¼š
        è¾“å…¥ï¼š
            REPORT_DATE  | STD_ITEM_NAME | AMOUNT
            2024-12-31   | æ€»èµ„äº§        | 1000000  â† ç¬¬1æ¬¡
            2024-12-31   | æ€»èµ„äº§        | 1000001  â† ç¬¬2æ¬¡ï¼ˆé‡å¤ï¼‰
            2024-12-31   | æ€»èµ„äº§        | 1000002  â† ç¬¬3æ¬¡ï¼ˆé‡å¤ï¼‰
            2024-12-31   | æ€»è´Ÿå€º        | 500000
        
        è¾“å‡ºï¼š
            REPORT_DATE  | STD_ITEM_NAME | AMOUNT
            2024-12-31   | æ€»èµ„äº§        | 1000000
            2024-12-31   | æ€»èµ„äº§_1      | 1000001
            2024-12-31   | æ€»èµ„äº§_2      | 1000002
            2024-12-31   | æ€»è´Ÿå€º        | 500000
    
    Args:
        df: åŒ…å« date_col, name_col, AMOUNT åˆ—çš„DataFrame
        date_col: æ—¥æœŸåˆ—å
        name_col: é¡¹ç›®åç§°åˆ—å
    
    Returns:
        é‡å‘½ååçš„DataFrame
    """
    if df.empty:
        return df
    
    df_clean = df[[date_col, name_col, 'AMOUNT']].copy()
    
    # è®¡ç®—æ¯ä¸ª(æ—¥æœŸ, é¡¹ç›®)ç»„åˆçš„å‡ºç°æ¬¡æ•°ï¼ˆä»0å¼€å§‹ï¼‰
    df_clean['_occurrence'] = df_clean.groupby([date_col, name_col]).cumcount()
    
    # æ£€æµ‹é‡å¤ï¼ˆoccurrence > 0 è¡¨ç¤ºç¬¬2æ¬¡åŠä»¥åå‡ºç°ï¼‰
    duplicates_mask = df_clean['_occurrence'] > 0
    duplicate_count = duplicates_mask.sum()
    
    if duplicate_count > 0:
        print(f"  â„¹ï¸  æ£€æµ‹åˆ° {duplicate_count} æ¡é‡å¤æ•°æ®ï¼Œæ·»åŠ åºå·åç¼€ï¼ˆé¿å…æ•°æ®ä¸¢å¤±ï¼‰")
        
        # ä¸ºé‡å¤é¡¹æ·»åŠ åç¼€ï¼šé¡¹ç›®å + "_" + åºå·
        df_clean.loc[duplicates_mask, name_col] = (
            df_clean.loc[duplicates_mask, name_col] + '_' + 
            df_clean.loc[duplicates_mask, '_occurrence'].astype(str)
        )
        
        # æ˜¾ç¤ºé‡å‘½åçš„ä¾‹å­ï¼ˆå‰5ä¸ªä¸åŒçš„é¡¹ç›®ï¼‰
        renamed_items = df_clean.loc[duplicates_mask, name_col].unique()
        if len(renamed_items) > 0:
            sample_count = min(5, len(renamed_items))
            print(f"    ç¤ºä¾‹: {', '.join(renamed_items[:sample_count])}")
            if len(renamed_items) > 5:
                print(f"    ... è¿˜æœ‰ {len(renamed_items) - 5} ä¸ª")
    
    # åˆ é™¤ä¸´æ—¶åˆ—
    df_clean = df_clean.drop(columns=['_occurrence'])
    
    return df_clean


def _get_base_column_name(col_name):
    """
    å»é™¤åˆ—åçš„æ‰€æœ‰åç¼€ï¼Œè·å–åŸºç¡€åç§°
    
    å¤„ç†çš„åç¼€ç±»å‹ï¼š
    - _æ•°å­—ï¼šå¦‚ _1, _2, _10
    - _x, _yï¼špandas merge è‡ªåŠ¨æ·»åŠ çš„åç¼€
    - åµŒå¥—åç¼€ï¼šå¦‚ _1_x, _2_y_x
    
    ç¤ºä¾‹ï¼š
        è´§å¸èµ„é‡‘_1_x_y â†’ è´§å¸èµ„é‡‘
        å­˜è´§_2         â†’ å­˜è´§
        è´§å¸èµ„é‡‘       â†’ è´§å¸èµ„é‡‘
        æ€»èµ„äº§_1_2_x   â†’ æ€»èµ„äº§
    
    Args:
        col_name: åˆ—å
    
    Returns:
        åŸºç¡€åˆ—åï¼ˆå»é™¤æ‰€æœ‰åç¼€ï¼‰
    """
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç§»é™¤æ‰€æœ‰ _æ•°å­—ã€_xã€_y åç¼€ï¼ˆå¯èƒ½æœ‰å¤šä¸ªï¼‰
    # + è¡¨ç¤ºåŒ¹é…1æ¬¡æˆ–å¤šæ¬¡ï¼Œ$ è¡¨ç¤ºå­—ç¬¦ä¸²ç»“å°¾
    base = re.sub(r'(_\d+|_[xy])+$', '', col_name)
    return base


def _unify_column_names(df, key_col='REPORT_DATE'):
    """
    ç»Ÿä¸€DataFrameä¸­çš„åˆ—åï¼Œå°†æ‰€æœ‰åç¼€é‡æ–°ç¼–å·ä¸ºè¿ç»­åºåˆ—
    
    å¤„ç†æµç¨‹ï¼š
    1. æå–æ¯åˆ—çš„åŸºç¡€åç§°ï¼ˆå»é™¤æ‰€æœ‰åç¼€ï¼‰
    2. æŒ‰åŸºç¡€åç§°åˆ†ç»„
    3. ä¸ºæ¯ç»„å†…çš„åˆ—æŒ‰å‡ºç°é¡ºåºé‡æ–°ç¼–å·ï¼šåŸºç¡€å, åŸºç¡€å_1, åŸºç¡€å_2, ...
    
    ç¤ºä¾‹ï¼š
        è¾“å…¥åˆ—åï¼š
            è´§å¸èµ„é‡‘, è´§å¸èµ„é‡‘_1, è´§å¸èµ„é‡‘_x, è´§å¸èµ„é‡‘_1_x, è´§å¸èµ„é‡‘_y, æ€»èµ„äº§, å­˜è´§, å­˜è´§_y
        
        åˆ†ç»„ï¼š
            è´§å¸èµ„é‡‘ç»„: [è´§å¸èµ„é‡‘, è´§å¸èµ„é‡‘_1, è´§å¸èµ„é‡‘_x, è´§å¸èµ„é‡‘_1_x, è´§å¸èµ„é‡‘_y]
            æ€»èµ„äº§ç»„: [æ€»èµ„äº§]
            å­˜è´§ç»„: [å­˜è´§, å­˜è´§_y]
        
        è¾“å‡ºåˆ—åï¼š
            è´§å¸èµ„é‡‘, è´§å¸èµ„é‡‘_1, è´§å¸èµ„é‡‘_2, è´§å¸èµ„é‡‘_3, è´§å¸èµ„é‡‘_4, æ€»èµ„äº§, å­˜è´§, å­˜è´§_1
    
    Args:
        df: DataFrame
        key_col: ä¸éœ€è¦é‡å‘½åçš„é”®åˆ—ï¼ˆå¦‚æ—¥æœŸåˆ—ï¼‰
    
    Returns:
        é‡å‘½ååçš„DataFrame
    """
    if df.empty:
        return df
    
    # æ”¶é›†æ‰€æœ‰åˆ—åï¼ˆé™¤äº†é”®åˆ—ï¼‰
    columns = [col for col in df.columns if col != key_col]
    
    # æŒ‰åŸºç¡€åç§°åˆ†ç»„
    column_groups = {}
    for col in columns:
        base_name = _get_base_column_name(col)
        if base_name not in column_groups:
            column_groups[base_name] = []
        column_groups[base_name].append(col)
    
    # ç”Ÿæˆé‡å‘½åå­—å…¸
    rename_dict = {}
    renamed_count = 0
    
    for base_name, col_list in column_groups.items():
        if len(col_list) == 1:
            # åªæœ‰ä¸€ä¸ªåˆ—ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å»æ‰åç¼€
            old_name = col_list[0]
            if old_name != base_name:
                # åŸåå¸¦åç¼€ï¼Œé‡å‘½åä¸ºåŸºç¡€å
                rename_dict[old_name] = base_name
                renamed_count += 1
        else:
            # æœ‰å¤šä¸ªåˆ—ï¼Œç»Ÿä¸€é‡å‘½å
            for idx, old_name in enumerate(col_list):
                if idx == 0:
                    new_name = base_name
                else:
                    new_name = f"{base_name}_{idx}"
                
                if old_name != new_name:
                    rename_dict[old_name] = new_name
                    renamed_count += 1
    
    if renamed_count > 0:
        print(f"  âœ“ ç»Ÿä¸€é‡å‘½åäº† {renamed_count} ä¸ªåˆ—")
        # æ˜¾ç¤ºéƒ¨åˆ†é‡å‘½åç¤ºä¾‹
        sample_renames = list(rename_dict.items())[:5]
        for old, new in sample_renames:
            print(f"    {old} â†’ {new}")
        if len(rename_dict) > 5:
            print(f"    ... è¿˜æœ‰ {len(rename_dict) - 5} ä¸ª")
    
    # æ‰§è¡Œé‡å‘½å
    df_renamed = df.rename(columns=rename_dict)
    
    return df_renamed


def _merge_tables_with_global_rename(tables, on='REPORT_DATE'):
    """
    åˆå¹¶å¤šä¸ªè¡¨ï¼Œå¹¶å¯¹æ‰€æœ‰åˆ—åè¿›è¡Œå…¨å±€ç»Ÿä¸€é‡å‘½å
    
    å¤„ç†æµç¨‹ï¼š
    1. ä½¿ç”¨pandas mergeé€ä¸ªåˆå¹¶è¡¨ï¼ˆè®©pandasè‡ªåŠ¨æ·»åŠ åç¼€ï¼‰
    2. åˆå¹¶å®Œæˆåï¼Œè°ƒç”¨å…¨å±€é‡å‘½åå‡½æ•°ç»Ÿä¸€æ‰€æœ‰åˆ—å
    
    Args:
        tables: DataFrameåˆ—è¡¨
        on: åˆå¹¶é”®ï¼ˆå¦‚ 'REPORT_DATE'ï¼‰
    
    Returns:
        åˆå¹¶å¹¶é‡å‘½ååçš„DataFrame
    """
    if not tables:
        return pd.DataFrame()
    
    if len(tables) == 1:
        return tables[0]
    
    # Step 1: é€ä¸ªåˆå¹¶è¡¨ï¼ˆä¸æŒ‡å®šsuffixesï¼Œè®©pandasè‡ªåŠ¨å¤„ç†ï¼‰
    result_df = tables[0]
    for i in range(1, len(tables)):
        result_df = pd.merge(
            result_df, 
            tables[i], 
            on=on, 
            how='outer'
            # ä¸æŒ‡å®šsuffixesï¼Œè®©pandasè‡ªåŠ¨æ·»åŠ _x, _y
        )
    
    print(f"  ğŸ“Š åˆå¹¶äº† {len(tables)} ä¸ªè¡¨ï¼Œå…± {len(result_df.columns) - 1} ä¸ªæ•°æ®åˆ—")
    
    # Step 2: å…¨å±€é‡å‘½åï¼Œç»Ÿä¸€æ‰€æœ‰åˆ—å
    print(f"  ğŸ”„ æ­£åœ¨è¿›è¡Œå…¨å±€åˆ—åç»Ÿä¸€...")
    result_df = _unify_column_names(result_df, key_col=on)
    
    return result_df


def _rename_duplicate_columns_in_single_df(df):
    """
    æ£€æŸ¥å¹¶é‡å‘½åå•ä¸ªDataFrameä¸­çš„é‡å¤åˆ—å
    
    å¤„ç†é€»è¾‘ï¼š
    å¯¹äºé‡å¤çš„åˆ—åï¼Œç¬¬1æ¬¡å‡ºç°ä¿æŒåŸåï¼Œåç»­å‡ºç°æ·»åŠ  _1, _2, ... åç¼€
    
    ç¤ºä¾‹ï¼š
        è¾“å…¥åˆ—åï¼š[REPORT_DATE, ROE, ROA, ROE, å‡€åˆ©æ¶¦, ROE, è¥ä¸šæ”¶å…¥]
        è¾“å‡ºåˆ—åï¼š[REPORT_DATE, ROE, ROA, ROE_1, å‡€åˆ©æ¶¦, ROE_2, è¥ä¸šæ”¶å…¥]
    
    Args:
        df: DataFrame
    
    Returns:
        é‡å‘½ååçš„DataFrame
    """
    if df.empty:
        return df
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤åˆ—å
    if not df.columns.duplicated().any():
        return df
    
    # é‡å‘½åé‡å¤åˆ—
    seen = {}
    new_columns = []
    renamed_count = 0
    
    for col in df.columns:
        if col not in seen:
            seen[col] = 0
            new_columns.append(col)  # ç¬¬1æ¬¡å‡ºç°ï¼Œä¿æŒåŸå
        else:
            seen[col] += 1
            new_col = f"{col}_{seen[col]}"
            new_columns.append(new_col)  # ç¬¬2æ¬¡åŠä»¥åï¼Œæ·»åŠ åç¼€
            renamed_count += 1
    
    if renamed_count > 0:
        print(f"  â„¹ï¸  æ£€æµ‹åˆ° {renamed_count} ä¸ªé‡å¤åˆ—åï¼Œå·²é‡å‘½å")
        df_renamed = df.copy()
        df_renamed.columns = new_columns
        return df_renamed
    
    return df


# ==================== Aè‚¡æ•°æ®è·å–å‡½æ•° ====================

def a_financial_indicator(stock_code, indicator="æŒ‰å•å­£åº¦"):
    """è·å–Aè‚¡è´¢åŠ¡æŒ‡æ ‡
    
    Args:
        stock_code (str): è‚¡ç¥¨ä»£ç ï¼Œå¦‚ '002594'
        indicator (str): æŒ‡æ ‡ç±»å‹ã€‚å¯é€‰å€¼ï¼š
            - "æŒ‰å•å­£åº¦": ä»…è·å–æŒ‰å•å­£åº¦çš„æ•°æ®ï¼ˆé»˜è®¤ï¼‰
            - "æŒ‰æŠ¥å‘ŠæœŸ": ä»…è·å–æŒ‰æŠ¥å‘ŠæœŸçš„æ•°æ®
            - "å…¨éƒ¨": åŒæ—¶è·å–æŒ‰å•å­£åº¦å’ŒæŒ‰æŠ¥å‘ŠæœŸçš„æ•°æ®
    
    Returns:
        pd.DataFrame æˆ– dict: 
            - å½“indicatorä¸º"æŒ‰å•å­£åº¦"æˆ–"æŒ‰æŠ¥å‘ŠæœŸ"æ—¶ï¼Œè¿”å›DataFrame
            - å½“indicatorä¸º"å…¨éƒ¨"æ—¶ï¼Œè¿”å›å­—å…¸ï¼ŒåŒ…å«ä¸¤ä¸ªé”®ï¼š"æŒ‰å•å­£åº¦"å’Œ"æŒ‰æŠ¥å‘ŠæœŸ"
    """
    prefix = stock_code[:2]
    if prefix in ['60','68']:
        stock_code = stock_code + '.SH'
    elif prefix in ['00','30']:
        stock_code = stock_code + '.SZ'
    
    # æ ¹æ®indicatorå‚æ•°è¿”å›ç›¸åº”æ•°æ®
    if indicator == "æŒ‰å•å­£åº¦":
        df = ak.stock_financial_analysis_indicator_em(symbol=stock_code, indicator="æŒ‰å•å­£åº¦")
        return df
    elif indicator == "æŒ‰æŠ¥å‘ŠæœŸ":
        df = ak.stock_financial_analysis_indicator_em(symbol=stock_code, indicator="æŒ‰æŠ¥å‘ŠæœŸ")
        return df
    elif indicator == "å…¨éƒ¨":
        df_quarterly = ak.stock_financial_analysis_indicator_em(symbol=stock_code, indicator="æŒ‰å•å­£åº¦")
        df_report = ak.stock_financial_analysis_indicator_em(symbol=stock_code, indicator="æŒ‰æŠ¥å‘ŠæœŸ")
        return {
            "æŒ‰å•å­£åº¦": df_quarterly,
            "æŒ‰æŠ¥å‘ŠæœŸ": df_report
        }
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„indicatorç±»å‹: {indicator}ã€‚å¯é€‰å€¼ï¼š'æŒ‰å•å­£åº¦', 'æŒ‰æŠ¥å‘ŠæœŸ', 'å…¨éƒ¨'")


def a_financial_statements(stock_code):
    """è·å–Aè‚¡è´¢åŠ¡æŠ¥è¡¨æ•°æ®ï¼ˆæ”¹è¿›ç‰ˆï¼šä½¿ç”¨å…¨å±€é‡å‘½åï¼‰
    
    æ”¹è¿›è¯´æ˜ï¼š
    - ä¿ç•™æ‰€æœ‰æŠ¥è¡¨æ•°æ®
    - ä½¿ç”¨å…¨å±€é‡å‘½åç»Ÿä¸€åˆ—å
    
    Args:
        stock_code (str): Aè‚¡è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ï¼š'000001', '600519', '002594'
    
    Returns:
        pd.DataFrame: åˆå¹¶åçš„è´¢åŠ¡æŠ¥è¡¨æ•°æ®
    """
    prefix = stock_code[:2]
    if prefix in ['60','68']:
        stock_code = 'SH' + stock_code
    elif prefix in ['00','30']:
        stock_code = 'SZ' + stock_code

    func_tuple = (
        "stock_balance_sheet_by_report_em",      # èµ„äº§è´Ÿå€ºè¡¨
        "stock_profit_sheet_by_quarterly_em",    # åˆ©æ¶¦è¡¨
        "stock_cash_flow_sheet_by_quarterly_em"  # ç°é‡‘æµé‡è¡¨
    )
    tables = []

    for i, func in enumerate(func_tuple):
        try:
            df = getattr(ak, func)(stock_code)
            if not df.empty:
                tables.append(df)
                print(f"  âœ“ è·å–{func}æˆåŠŸï¼Œå…±{len(df)}æ¡è®°å½•")
        except Exception as e:
            print(f"  âœ— è·å– {func} å¤±è´¥: {e}")
            continue

    if not tables:
        return pd.DataFrame()

    # ä½¿ç”¨å…¨å±€é‡å‘½åæ–¹å¼åˆå¹¶
    print(f"  ğŸ”„ æ­£åœ¨åˆå¹¶Aè‚¡è´¢åŠ¡æŠ¥è¡¨...")
    result_df = _merge_tables_with_global_rename(tables, on='REPORT_DATE')
    
    # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®ï¼Œé¿å…Excelä¿å­˜é—®é¢˜
    result_df = result_df.copy()
    
    # è½¬æ¢æ—¥æœŸåˆ—ä¸ºå­—ç¬¦ä¸²ï¼Œé¿å…Excelä¿å­˜é—®é¢˜
    if 'REPORT_DATE' in result_df.columns:
        result_df['REPORT_DATE'] = result_df['REPORT_DATE'].astype(str)
    if 'NOTICE_DATE' in result_df.columns:
        result_df['NOTICE_DATE'] = result_df['NOTICE_DATE'].astype(str)
    
    return result_df.sort_values('REPORT_DATE', ascending=False)


def get_full_financial_data_a(stock_code, indicator_type="æŒ‰å•å­£åº¦"):
    """
    è·å–Aè‚¡å®Œæ•´è´¢åŠ¡æ•°æ®ï¼ˆv0.5 ç‰ˆæœ¬ï¼‰
    
    v0.5: ä¿æŒä¸ v0.4 ç›¸åŒçš„åŠŸèƒ½
    v0.4: ä¿æŒä¸ v0.3 ç›¸åŒçš„åŠŸèƒ½
    v0.3: ä¿æŒä¸ v0.2 ç›¸åŒçš„åŠŸèƒ½
    v0.2 æ”¹è¿›ï¼š
    - âœ… è´¢åŠ¡æŒ‡æ ‡è·å–å¤±è´¥æ—¶ï¼Œç»§ç»­è·å–è´¢åŠ¡æŠ¥è¡¨
    - âœ… è®°å½•æ¯ä¸ªæ•°æ®æºçš„è·å–çŠ¶æ€
    - âœ… å³ä½¿éƒ¨åˆ†æ•°æ®ç¼ºå¤±ï¼Œä¹Ÿè¿”å›å·²è·å–çš„æ•°æ®
    
    åŒ…å«ï¼šè´¢åŠ¡æŒ‡æ ‡ + è´¢åŠ¡æŠ¥è¡¨ï¼Œæ‰€æœ‰é‡å¤åˆ—åç»Ÿä¸€ç¼–å·
    
    Args:
        stock_code (str): Aè‚¡è‚¡ç¥¨ä»£ç ï¼Œå¦‚ '600519'
        indicator_type (str): è´¢åŠ¡æŒ‡æ ‡ç±»å‹ï¼Œå¯é€‰ï¼š
            - "æŒ‰å•å­£åº¦": è·å–å•å­£åº¦è´¢åŠ¡æŒ‡æ ‡ï¼ˆé»˜è®¤ï¼‰
            - "æŒ‰æŠ¥å‘ŠæœŸ": è·å–æŠ¥å‘ŠæœŸè´¢åŠ¡æŒ‡æ ‡
    
    Returns:
        tuple: (DataFrame, dict)
            - DataFrame: åˆå¹¶åçš„å®Œæ•´è´¢åŠ¡æ•°æ®
            - dict: è·å–çŠ¶æ€ä¿¡æ¯
                {
                    'indicator': {'success': bool, 'error': str or None},
                    'statements': {'success': bool, 'error': str or None},
                    'data_sources': list  # æˆåŠŸè·å–çš„æ•°æ®æºåˆ—è¡¨
                }
    
    ç¤ºä¾‹ï¼š
        >>> df, status = get_full_financial_data_a('600519')
        >>> print(status)
        {'indicator': {'success': True, 'error': None},
         'statements': {'success': True, 'error': None},
         'data_sources': ['indicator', 'statements']}
    """
    print(f"\n{'='*60}")
    print(f"æ­£åœ¨è·å–Aè‚¡ {stock_code} å®Œæ•´è´¢åŠ¡æ•°æ®ï¼ˆ{indicator_type}ï¼‰")
    print(f"{'='*60}")
    
    # åˆå§‹åŒ–çŠ¶æ€è®°å½•
    status = {
        'indicator': {'success': False, 'error': None},
        'statements': {'success': False, 'error': None},
        'data_sources': []
    }
    
    # ç”¨äºå­˜å‚¨æˆåŠŸè·å–çš„æ•°æ®
    available_tables = []
    
    # 1. å°è¯•è·å–è´¢åŠ¡æŒ‡æ ‡
    print(f"[1/3] è·å–è´¢åŠ¡æŒ‡æ ‡ï¼ˆ{indicator_type}ï¼‰...")
    indicator_df = None
    try:
        indicator_df = a_financial_indicator(stock_code, indicator=indicator_type)
        
        if indicator_df is not None and not indicator_df.empty:
            print(f"  âœ“ è·å–æˆåŠŸï¼š{len(indicator_df)} è¡Œ Ã— {len(indicator_df.columns)} åˆ—")
            # å¤„ç†indicatorè¡¨æ ¼å†…çš„é‡å¤åˆ—
            indicator_df = _rename_duplicate_columns_in_single_df(indicator_df)
            available_tables.append(indicator_df)
            status['indicator']['success'] = True
            status['data_sources'].append('indicator')
        else:
            print("  âš ï¸  è´¢åŠ¡æŒ‡æ ‡æ•°æ®ä¸ºç©º")
            status['indicator']['error'] = "æ•°æ®ä¸ºç©º"
    except Exception as e:
        error_msg = f"{type(e).__name__}: {str(e)}"
        print(f"  âœ— è´¢åŠ¡æŒ‡æ ‡è·å–å¤±è´¥: {error_msg}")
        status['indicator']['error'] = error_msg
    
    # 2. å°è¯•è·å–è´¢åŠ¡æŠ¥è¡¨ï¼ˆæ— è®ºæŒ‡æ ‡æ˜¯å¦æˆåŠŸï¼‰
    print(f"[2/3] è·å–è´¢åŠ¡æŠ¥è¡¨...")
    statements_df = None
    try:
        statements_df = a_financial_statements(stock_code)
        
        if statements_df is not None and not statements_df.empty:
            print(f"  âœ“ è´¢åŠ¡æŠ¥è¡¨è·å–æˆåŠŸ")
            available_tables.append(statements_df)
            status['statements']['success'] = True
            status['data_sources'].append('statements')
        else:
            print("  âš ï¸  è´¢åŠ¡æŠ¥è¡¨æ•°æ®ä¸ºç©º")
            status['statements']['error'] = "æ•°æ®ä¸ºç©º"
    except Exception as e:
        error_msg = f"{type(e).__name__}: {str(e)}"
        print(f"  âœ— è´¢åŠ¡æŠ¥è¡¨è·å–å¤±è´¥: {error_msg}")
        status['statements']['error'] = error_msg
    
    # 3. åˆå¹¶å¯ç”¨çš„æ•°æ®
    print(f"[3/3] åˆå¹¶æ•°æ®...")
    
    if not available_tables:
        print(f"\nâŒ Aè‚¡ {stock_code} æ•°æ®è·å–å¤±è´¥ï¼šæ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å–")
        print(f"{'='*60}\n")
        return pd.DataFrame(), status
    
    if len(available_tables) == 1:
        result_df = available_tables[0]
        print(f"  â„¹ï¸  ä»…è·å–åˆ° {status['data_sources'][0]} æ•°æ®")
    else:
        # åˆå¹¶å¤šä¸ªæ•°æ®æº
        result_df = _merge_tables_with_global_rename(available_tables, on='REPORT_DATE')
    
    print(f"\nâœ… Aè‚¡ {stock_code} æ•°æ®è·å–å®Œæˆ")
    print(f"   æœ€ç»ˆæ•°æ®ï¼š{len(result_df)} è¡Œ Ã— {len(result_df.columns)} åˆ—")
    print(f"   æ•°æ®æ¥æºï¼š{', '.join(status['data_sources'])}")
    if status['indicator']['error'] or status['statements']['error']:
        print(f"   âš ï¸  éƒ¨åˆ†æ•°æ®è·å–å¤±è´¥ï¼š")
        if status['indicator']['error']:
            print(f"      - è´¢åŠ¡æŒ‡æ ‡: {status['indicator']['error']}")
        if status['statements']['error']:
            print(f"      - è´¢åŠ¡æŠ¥è¡¨: {status['statements']['error']}")
    print(f"{'='*60}\n")
    
    return result_df.sort_values('REPORT_DATE', ascending=False), status


# ==================== æ¸¯è‚¡æ•°æ®è·å–å‡½æ•° ====================

def _get_hk_financial_indicator(stock_code, indicator="æŠ¥å‘ŠæœŸ"):
    """è·å–æ¸¯è‚¡è´¢åŠ¡æŒ‡æ ‡ï¼ˆv0.5 æ”¯æŒå‘¨æœŸå‚æ•°ï¼‰
    
    Args:
        stock_code (str): æ¸¯è‚¡ä»£ç ï¼Œå¦‚ '00700'
        indicator (str): æŒ‡æ ‡å‘¨æœŸï¼Œå¯é€‰å€¼ï¼š
            - "æŠ¥å‘ŠæœŸ": è·å–æŠ¥å‘ŠæœŸæ•°æ®ï¼ˆé»˜è®¤ï¼‰
            - "å¹´åº¦": è·å–å¹´åº¦æ•°æ®
    
    Returns:
        pd.DataFrame: è´¢åŠ¡æŒ‡æ ‡æ•°æ®
    """
    df = ak.stock_financial_hk_analysis_indicator_em(symbol=stock_code, indicator=indicator)
    return df


def _get_hk_financial_statements(stock_code, indicator="æŠ¥å‘ŠæœŸ"):
    """è·å–æ¸¯è‚¡è´¢åŠ¡æŠ¥è¡¨æ•°æ®ï¼ˆv0.5 æ”¯æŒå‘¨æœŸå‚æ•°ï¼‰
    
    æ”¹è¿›è¯´æ˜ï¼š
    1. Pivotå‰é‡å‘½åï¼šä¿ç•™åŒä¸€æŠ¥è¡¨å†…çš„æ‰€æœ‰é‡å¤æ•°æ®
    2. å…¨å±€é‡å‘½åï¼šç»Ÿä¸€æ‰€æœ‰æŠ¥è¡¨åˆå¹¶åçš„åˆ—å
    3. å‘¨æœŸå‚æ•°ï¼šæ”¯æŒ"å¹´åº¦"å’Œ"æŠ¥å‘ŠæœŸ"
    
    Args:
        stock_code (str): æ¸¯è‚¡ä»£ç ï¼Œå¦‚ '00700'
        indicator (str): æŠ¥è¡¨å‘¨æœŸï¼Œå¯é€‰å€¼ï¼š
            - "æŠ¥å‘ŠæœŸ": è·å–æŠ¥å‘ŠæœŸæ•°æ®ï¼ˆé»˜è®¤ï¼‰
            - "å¹´åº¦": è·å–å¹´åº¦æ•°æ®
    
    Returns:
        pd.DataFrame: åˆå¹¶åçš„è´¢åŠ¡æŠ¥è¡¨æ•°æ®
    """
    reports = ["èµ„äº§è´Ÿå€ºè¡¨", "åˆ©æ¶¦è¡¨", "ç°é‡‘æµé‡è¡¨"]
    tables = []
    
    for report in reports:
        try:
            df = ak.stock_financial_hk_report_em(stock=stock_code, symbol=report, indicator=indicator)
            
            if df.empty:
                print(f"  âš ï¸  {report}æ— æ•°æ®")
                continue
            
            # â­ æ”¹è¿›1ï¼šé‡å‘½åé‡å¤é¡¹è€Œä¸æ˜¯åˆ é™¤ï¼ˆé¿å…æ•°æ®ä¸¢å¤±ï¼‰
            df_clean = _rename_duplicates_before_pivot(
                df, 
                date_col='REPORT_DATE', 
                name_col='STD_ITEM_NAME'
            )
            
            # æ‰§è¡Œpivotæ“ä½œï¼ˆç°åœ¨ä¸ä¼šæŠ¥é”™äº†ï¼‰
            df_pivoted = (df_clean.pivot(index='REPORT_DATE', columns='STD_ITEM_NAME', values='AMOUNT')
                          .reset_index())
            
            tables.append(df_pivoted)
            print(f"  âœ“ {report}å¤„ç†å®Œæˆï¼Œå…±{len(df_pivoted)}æ¡è®°å½•ï¼Œ{len(df_pivoted.columns)-1}ä¸ªå­—æ®µ")
            
        except Exception as e:
            print(f"  âœ— å¤„ç†{report}å¤±è´¥: {e}")
            continue
    
    if not tables:
        return pd.DataFrame()
    
    # â­ æ”¹è¿›2ï¼šä½¿ç”¨å…¨å±€é‡å‘½åæ–¹å¼åˆå¹¶
    print(f"  ğŸ”„ æ­£åœ¨åˆå¹¶æ¸¯è‚¡è´¢åŠ¡æŠ¥è¡¨...")
    result_df = _merge_tables_with_global_rename(tables, on='REPORT_DATE')
    
    return result_df.sort_values('REPORT_DATE', ascending=False)


def get_full_financial_data_hk(stock_code, indicator="æŠ¥å‘ŠæœŸ"):
    """
    è·å–æ¸¯è‚¡å®Œæ•´è´¢åŠ¡æ•°æ®ï¼ˆv0.5 æ”¯æŒå‘¨æœŸå‚æ•°ï¼‰
    
    v0.5: ä¿æŒä¸ v0.4 ç›¸åŒçš„åŠŸèƒ½
    v0.4: ä¿æŒä¸ v0.3 ç›¸åŒçš„åŠŸèƒ½
    v0.3 æ–°å¢ï¼š
    - âœ… æ”¯æŒå‘¨æœŸå‚æ•°ï¼šå¯é€‰æ‹©"æŠ¥å‘ŠæœŸ"æˆ–"å¹´åº¦"
    - âœ… å‘åå…¼å®¹ï¼šé»˜è®¤å€¼ä¸º"æŠ¥å‘ŠæœŸ"ï¼Œä¸å½±å“ç°æœ‰ä»£ç 
    
    v0.2 åŸºç¡€åŠŸèƒ½ï¼š
    - âœ… è´¢åŠ¡æŒ‡æ ‡è·å–å¤±è´¥æ—¶ï¼Œç»§ç»­è·å–è´¢åŠ¡æŠ¥è¡¨
    - âœ… è®°å½•æ¯ä¸ªæ•°æ®æºçš„è·å–çŠ¶æ€
    - âœ… å³ä½¿éƒ¨åˆ†æ•°æ®ç¼ºå¤±ï¼Œä¹Ÿè¿”å›å·²è·å–çš„æ•°æ®
    
    åŒ…å«ï¼šè´¢åŠ¡æŒ‡æ ‡ + è´¢åŠ¡æŠ¥è¡¨ï¼Œæ‰€æœ‰é‡å¤åˆ—åç»Ÿä¸€ç¼–å·
    
    Args:
        stock_code (str): æ¸¯è‚¡ä»£ç ï¼Œå¦‚ '00700'
        indicator (str): æ•°æ®å‘¨æœŸï¼Œå¯é€‰å€¼ï¼š
            - "æŠ¥å‘ŠæœŸ": è·å–æŠ¥å‘ŠæœŸæ•°æ®ï¼ˆé»˜è®¤ï¼‰
            - "å¹´åº¦": è·å–å¹´åº¦æ•°æ®
    
    Returns:
        tuple: (DataFrame, dict)
            - DataFrame: åˆå¹¶åçš„å®Œæ•´è´¢åŠ¡æ•°æ®
            - dict: è·å–çŠ¶æ€ä¿¡æ¯
    
    ç¤ºä¾‹ï¼š
        >>> # ä½¿ç”¨é»˜è®¤å‘¨æœŸï¼ˆæŠ¥å‘ŠæœŸï¼‰
        >>> df, status = get_full_financial_data_hk('00700')
        
        >>> # æŒ‡å®šå¹´åº¦æ•°æ®
        >>> df, status = get_full_financial_data_hk('00700', indicator='å¹´åº¦')
    """
    print(f"\n{'='*60}")
    print(f"æ­£åœ¨è·å–æ¸¯è‚¡ {stock_code} å®Œæ•´è´¢åŠ¡æ•°æ®ï¼ˆ{indicator}ï¼‰")
    print(f"{'='*60}")
    
    # åˆå§‹åŒ–çŠ¶æ€è®°å½•
    status = {
        'indicator': {'success': False, 'error': None},
        'statements': {'success': False, 'error': None},
        'data_sources': []
    }
    
    # ç”¨äºå­˜å‚¨æˆåŠŸè·å–çš„æ•°æ®
    available_tables = []
    
    # 1. å°è¯•è·å–è´¢åŠ¡æŒ‡æ ‡
    print(f"[1/3] è·å–è´¢åŠ¡æŒ‡æ ‡ï¼ˆ{indicator}ï¼‰...")
    indicator_df = None
    try:
        indicator_df = _get_hk_financial_indicator(stock_code, indicator=indicator)
        
        if indicator_df is not None and not indicator_df.empty:
            print(f"  âœ“ è·å–æˆåŠŸï¼š{len(indicator_df)} è¡Œ Ã— {len(indicator_df.columns)} åˆ—")
            # å¤„ç†indicatorè¡¨æ ¼å†…çš„é‡å¤åˆ—
            indicator_df = _rename_duplicate_columns_in_single_df(indicator_df)
            available_tables.append(indicator_df)
            status['indicator']['success'] = True
            status['data_sources'].append('indicator')
        else:
            print("  âš ï¸  è´¢åŠ¡æŒ‡æ ‡æ•°æ®ä¸ºç©º")
            status['indicator']['error'] = "æ•°æ®ä¸ºç©º"
    except Exception as e:
        error_msg = f"{type(e).__name__}: {str(e)}"
        print(f"  âœ— è´¢åŠ¡æŒ‡æ ‡è·å–å¤±è´¥: {error_msg}")
        status['indicator']['error'] = error_msg
    
    # 2. å°è¯•è·å–è´¢åŠ¡æŠ¥è¡¨ï¼ˆæ— è®ºæŒ‡æ ‡æ˜¯å¦æˆåŠŸï¼‰
    print(f"[2/3] è·å–è´¢åŠ¡æŠ¥è¡¨ï¼ˆ{indicator}ï¼‰...")
    statements_df = None
    try:
        statements_df = _get_hk_financial_statements(stock_code, indicator=indicator)
        
        if statements_df is not None and not statements_df.empty:
            print(f"  âœ“ è´¢åŠ¡æŠ¥è¡¨è·å–æˆåŠŸ")
            available_tables.append(statements_df)
            status['statements']['success'] = True
            status['data_sources'].append('statements')
        else:
            print("  âš ï¸  è´¢åŠ¡æŠ¥è¡¨æ•°æ®ä¸ºç©º")
            status['statements']['error'] = "æ•°æ®ä¸ºç©º"
    except Exception as e:
        error_msg = f"{type(e).__name__}: {str(e)}"
        print(f"  âœ— è´¢åŠ¡æŠ¥è¡¨è·å–å¤±è´¥: {error_msg}")
        status['statements']['error'] = error_msg
    
    # 3. åˆå¹¶å¯ç”¨çš„æ•°æ®
    print(f"[3/3] åˆå¹¶æ•°æ®...")
    
    if not available_tables:
        print(f"\nâŒ æ¸¯è‚¡ {stock_code} æ•°æ®è·å–å¤±è´¥ï¼šæ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å–")
        print(f"{'='*60}\n")
        return pd.DataFrame(), status
    
    if len(available_tables) == 1:
        result_df = available_tables[0]
        print(f"  â„¹ï¸  ä»…è·å–åˆ° {status['data_sources'][0]} æ•°æ®")
    else:
        # åˆå¹¶å¤šä¸ªæ•°æ®æº
        result_df = _merge_tables_with_global_rename(available_tables, on='REPORT_DATE')
    
    print(f"\nâœ… æ¸¯è‚¡ {stock_code} æ•°æ®è·å–å®Œæˆ")
    print(f"   æœ€ç»ˆæ•°æ®ï¼š{len(result_df)} è¡Œ Ã— {len(result_df.columns)} åˆ—")
    print(f"   æ•°æ®æ¥æºï¼š{', '.join(status['data_sources'])}")
    if status['indicator']['error'] or status['statements']['error']:
        print(f"   âš ï¸  éƒ¨åˆ†æ•°æ®è·å–å¤±è´¥ï¼š")
        if status['indicator']['error']:
            print(f"      - è´¢åŠ¡æŒ‡æ ‡: {status['indicator']['error']}")
        if status['statements']['error']:
            print(f"      - è´¢åŠ¡æŠ¥è¡¨: {status['statements']['error']}")
    print(f"{'='*60}\n")
    
    return result_df.sort_values('REPORT_DATE', ascending=False), status


# ==================== ç¾è‚¡æ•°æ®è·å–å‡½æ•° ====================

def _get_us_financial_indicator(stock_code, indicator="å•å­£æŠ¥"):
    """è·å–ç¾è‚¡è´¢åŠ¡æŒ‡æ ‡ï¼ˆv0.5 ä½¿ç”¨ä¼˜åŒ–ç‰ˆAPIï¼‰
    
    v0.4 æ”¹è¿›ï¼š
    - ä½¿ç”¨è‡ªå®šä¹‰å®ç°æ›¿ä»£akshareï¼Œç›´æ¥è°ƒç”¨ä¸œæ–¹è´¢å¯ŒAPI
    - æ ¹æ®å…¬å¸ç±»å‹ï¼ˆä¸€èˆ¬ä¼ä¸š/é“¶è¡Œ/ä¿é™©ï¼‰è‡ªåŠ¨é€‰æ‹©å¯¹åº”APIæ¥å£
    - æ”¯æŒæ›´å®Œæ•´çš„æ•°æ®å­—æ®µ
    
    Args:
        stock_code (str): ç¾è‚¡ä»£ç ï¼Œå¦‚ 'AAPL'
        indicator (str): æŒ‡æ ‡å‘¨æœŸï¼Œå¯é€‰å€¼ï¼š
            - "å•å­£æŠ¥": è·å–å•å­£åº¦æ•°æ®ï¼ˆé»˜è®¤ï¼‰
            - "å¹´æŠ¥": è·å–å¹´åº¦æ•°æ®
            - "ç´¯è®¡å­£æŠ¥": è·å–ç´¯è®¡å­£åº¦æ•°æ®
    
    Returns:
        pd.DataFrame: è´¢åŠ¡æŒ‡æ ‡æ•°æ®
    """
    df = stock_financial_us_analysis_indicator_em(symbol=stock_code, indicator=indicator)
    return df


def _get_us_financial_statements(stock_code, indicator="å•å­£æŠ¥"):
    """è·å–ç¾è‚¡è´¢åŠ¡æ•°æ®ï¼ˆv0.5 æ”¯æŒå‘¨æœŸå‚æ•°ï¼‰
    
    æ”¹è¿›è¯´æ˜ï¼š
    1. Pivotå‰é‡å‘½åï¼šä¿ç•™åŒä¸€æŠ¥è¡¨å†…çš„æ‰€æœ‰é‡å¤æ•°æ®
    2. å…¨å±€é‡å‘½åï¼šç»Ÿä¸€æ‰€æœ‰æŠ¥è¡¨åˆå¹¶åçš„åˆ—å
    3. å‘¨æœŸå‚æ•°ï¼šæ”¯æŒ"å¹´æŠ¥"ã€"å•å­£æŠ¥"ã€"ç´¯è®¡å­£æŠ¥"
    
    Args:
        stock_code (str): ç¾è‚¡ä»£ç ï¼Œå¦‚ 'AAPL'
        indicator (str): æŠ¥è¡¨å‘¨æœŸï¼Œå¯é€‰å€¼ï¼š
            - "å•å­£æŠ¥": è·å–å•å­£åº¦æ•°æ®ï¼ˆé»˜è®¤ï¼‰
            - "å¹´æŠ¥": è·å–å¹´åº¦æ•°æ®
            - "ç´¯è®¡å­£æŠ¥": è·å–ç´¯è®¡å­£åº¦æ•°æ®
    
    Returns:
        pd.DataFrame: åˆå¹¶åçš„è´¢åŠ¡æŠ¥è¡¨æ•°æ®
    """
    configs = {
        "èµ„äº§è´Ÿå€ºè¡¨": [indicator],
        "ç»¼åˆæŸç›Šè¡¨": [indicator],
        "ç°é‡‘æµé‡è¡¨": [indicator]
    }

    tables = []
    for symbol, indicators in configs.items():
        dfs = []
        for ind in indicators:
            try:
                df = ak.stock_financial_us_report_em(stock=stock_code, symbol=symbol, indicator=ind)
                
                if df.empty:
                    print(f"  âš ï¸  {symbol}-{ind}æ— æ•°æ®")
                    continue
                
                # â­ æ”¹è¿›1ï¼šé‡å‘½åé‡å¤é¡¹è€Œä¸æ˜¯åˆ é™¤ï¼ˆé¿å…æ•°æ®ä¸¢å¤±ï¼‰
                df_clean = _rename_duplicates_before_pivot(
                    df, 
                    date_col='REPORT_DATE', 
                    name_col='ITEM_NAME'
                )
                
                # æ‰§è¡Œpivotæ“ä½œ
                df_pivoted = (df_clean.pivot(index='REPORT_DATE', columns='ITEM_NAME', values='AMOUNT')
                              .reset_index())
                
                dfs.append(df_pivoted)
                print(f"  âœ“ {symbol}-{ind}å¤„ç†å®Œæˆï¼Œå…±{len(df_pivoted)}æ¡è®°å½•ï¼Œ{len(df_pivoted.columns)-1}ä¸ªå­—æ®µ")
                
            except Exception as e:
                print(f"  âœ— å¤„ç†{symbol}-{ind}å¤±è´¥: {e}")
                continue
        
        if dfs:
            # åˆå¹¶åŒä¸€æŠ¥è¡¨çš„ä¸åŒindicatorï¼ˆå¦‚æœæœ‰å¤šä¸ªï¼‰
            combined = pd.concat(dfs, ignore_index=True) if len(dfs) > 1 else dfs[0]
            tables.append(combined)
    
    if not tables:
        return pd.DataFrame()
    
    # â­ æ”¹è¿›2ï¼šä½¿ç”¨å…¨å±€é‡å‘½åæ–¹å¼åˆå¹¶
    print(f"  ğŸ”„ æ­£åœ¨åˆå¹¶ç¾è‚¡è´¢åŠ¡æŠ¥è¡¨...")
    result_df = _merge_tables_with_global_rename(tables, on='REPORT_DATE')
    
    return result_df.sort_values('REPORT_DATE', ascending=False)


def get_full_financial_data_us(stock_code, indicator="å•å­£æŠ¥"):
    """
    è·å–ç¾è‚¡å®Œæ•´è´¢åŠ¡æ•°æ®ï¼ˆv0.5 ç¾è‚¡æŒ‡æ ‡APIä¼˜åŒ–ç‰ˆï¼‰
    
    v0.5: ä¿æŒä¸ v0.4 ç›¸åŒçš„åŠŸèƒ½
    v0.4 æ–°å¢ï¼š
    - âœ… ç¾è‚¡è´¢åŠ¡æŒ‡æ ‡APIä¼˜åŒ–ï¼šä½¿ç”¨è‡ªå®šä¹‰å®ç°ï¼Œç›´æ¥è°ƒç”¨ä¸œæ–¹è´¢å¯ŒAPI
    - âœ… æ”¯æŒä¸åŒä¼ä¸šç±»å‹ï¼šè‡ªåŠ¨è¯†åˆ«ä¸€èˆ¬ä¼ä¸š/é“¶è¡Œ/ä¿é™©ï¼Œé€‰æ‹©å¯¹åº”APIæ¥å£
    
    v0.3 åŸºç¡€åŠŸèƒ½ï¼š
    - âœ… æ”¯æŒå‘¨æœŸå‚æ•°ï¼šå¯é€‰æ‹©"å¹´æŠ¥"ã€"å•å­£æŠ¥"ã€"ç´¯è®¡å­£æŠ¥"
    - âœ… å‘åå…¼å®¹ï¼šé»˜è®¤å€¼ä¸º"å•å­£æŠ¥"ï¼Œä¸å½±å“ç°æœ‰ä»£ç 
    
    v0.2 åŸºç¡€åŠŸèƒ½ï¼š
    - âœ… è´¢åŠ¡æŒ‡æ ‡è·å–å¤±è´¥æ—¶ï¼Œç»§ç»­è·å–è´¢åŠ¡æŠ¥è¡¨ï¼ˆè§£å†³ACGLç­‰å…¬å¸çš„é—®é¢˜ï¼‰
    - âœ… è®°å½•æ¯ä¸ªæ•°æ®æºçš„è·å–çŠ¶æ€
    - âœ… å³ä½¿éƒ¨åˆ†æ•°æ®ç¼ºå¤±ï¼Œä¹Ÿè¿”å›å·²è·å–çš„æ•°æ®
    
    åŒ…å«ï¼šè´¢åŠ¡æŒ‡æ ‡ + è´¢åŠ¡æŠ¥è¡¨ï¼Œæ‰€æœ‰é‡å¤åˆ—åç»Ÿä¸€ç¼–å·
    
    Args:
        stock_code (str): ç¾è‚¡ä»£ç ï¼Œå¦‚ 'AAPL', 'ACGL'
        indicator (str): æ•°æ®å‘¨æœŸï¼Œå¯é€‰å€¼ï¼š
            - "å•å­£æŠ¥": è·å–å•å­£åº¦æ•°æ®ï¼ˆé»˜è®¤ï¼‰
            - "å¹´æŠ¥": è·å–å¹´åº¦æ•°æ®
            - "ç´¯è®¡å­£æŠ¥": è·å–ç´¯è®¡å­£åº¦æ•°æ®
    
    Returns:
        tuple: (DataFrame, dict)
            - DataFrame: åˆå¹¶åçš„å®Œæ•´è´¢åŠ¡æ•°æ®
            - dict: è·å–çŠ¶æ€ä¿¡æ¯
                {
                    'indicator': {'success': bool, 'error': str or None},
                    'statements': {'success': bool, 'error': None},
                    'data_sources': list  # æˆåŠŸè·å–çš„æ•°æ®æºåˆ—è¡¨
                }
    
    ç¤ºä¾‹ï¼š
        >>> # ä½¿ç”¨é»˜è®¤å‘¨æœŸï¼ˆå•å­£æŠ¥ï¼‰
        >>> df, status = get_full_financial_data_us('AAPL')
        >>> print(status['data_sources'])
        ['indicator', 'statements']
        
        >>> # æŒ‡å®šå¹´æŠ¥æ•°æ®
        >>> df, status = get_full_financial_data_us('AAPL', indicator='å¹´æŠ¥')
        
        >>> # æŒ‡å®šç´¯è®¡å­£æŠ¥
        >>> df, status = get_full_financial_data_us('TSLA', indicator='ç´¯è®¡å­£æŠ¥')
    """
    print(f"\n{'='*60}")
    print(f"æ­£åœ¨è·å–ç¾è‚¡ {stock_code} å®Œæ•´è´¢åŠ¡æ•°æ®ï¼ˆ{indicator}ï¼‰")
    print(f"{'='*60}")
    
    # åˆå§‹åŒ–çŠ¶æ€è®°å½•
    status = {
        'indicator': {'success': False, 'error': None},
        'statements': {'success': False, 'error': None},
        'data_sources': []
    }
    
    # ç”¨äºå­˜å‚¨æˆåŠŸè·å–çš„æ•°æ®
    available_tables = []
    
    # 1. å°è¯•è·å–è´¢åŠ¡æŒ‡æ ‡ï¼ˆæ·»åŠ å®¹é”™å¤„ç†ï¼‰
    print(f"[1/3] è·å–è´¢åŠ¡æŒ‡æ ‡ï¼ˆ{indicator}ï¼‰...")
    indicator_df = None
    try:
        indicator_df = _get_us_financial_indicator(stock_code, indicator=indicator)
        
        if indicator_df is not None and not indicator_df.empty:
            print(f"  âœ“ è·å–æˆåŠŸï¼š{len(indicator_df)} è¡Œ Ã— {len(indicator_df.columns)} åˆ—")
            # å¤„ç†indicatorè¡¨æ ¼å†…çš„é‡å¤åˆ—
            indicator_df = _rename_duplicate_columns_in_single_df(indicator_df)
            available_tables.append(indicator_df)
            status['indicator']['success'] = True
            status['data_sources'].append('indicator')
        else:
            print("  âš ï¸  è´¢åŠ¡æŒ‡æ ‡æ•°æ®ä¸ºç©º")
            status['indicator']['error'] = "æ•°æ®ä¸ºç©º"
    except TypeError as e:
        # ä¸“é—¨å¤„ç† 'NoneType' object is not subscriptable é”™è¯¯
        if "'NoneType' object is not subscriptable" in str(e):
            error_msg = "ä¸œæ–¹è´¢å¯Œæ•°æ®åº“ä¸­æ— æ­¤å…¬å¸çš„è´¢åŠ¡æŒ‡æ ‡"
            print(f"  âš ï¸  è´¢åŠ¡æŒ‡æ ‡ä¸å¯ç”¨ï¼š{error_msg}")
            print(f"  â„¹ï¸  å°†ç»§ç»­è·å–è´¢åŠ¡æŠ¥è¡¨æ•°æ®...")
            status['indicator']['error'] = error_msg
        else:
            error_msg = f"TypeError: {str(e)}"
            print(f"  âœ— è´¢åŠ¡æŒ‡æ ‡è·å–å¤±è´¥: {error_msg}")
            status['indicator']['error'] = error_msg
    except Exception as e:
        error_msg = f"{type(e).__name__}: {str(e)}"
        print(f"  âœ— è´¢åŠ¡æŒ‡æ ‡è·å–å¤±è´¥: {error_msg}")
        status['indicator']['error'] = error_msg
    
    # 2. å°è¯•è·å–è´¢åŠ¡æŠ¥è¡¨ï¼ˆæ— è®ºæŒ‡æ ‡æ˜¯å¦æˆåŠŸï¼Œéƒ½ç»§ç»­æ‰§è¡Œï¼‰
    print(f"[2/3] è·å–è´¢åŠ¡æŠ¥è¡¨ï¼ˆ{indicator}ï¼‰...")
    statements_df = None
    try:
        statements_df = _get_us_financial_statements(stock_code, indicator=indicator)
        
        if statements_df is not None and not statements_df.empty:
            print(f"  âœ“ è´¢åŠ¡æŠ¥è¡¨è·å–æˆåŠŸ")
            available_tables.append(statements_df)
            status['statements']['success'] = True
            status['data_sources'].append('statements')
        else:
            print("  âš ï¸  è´¢åŠ¡æŠ¥è¡¨æ•°æ®ä¸ºç©º")
            status['statements']['error'] = "æ•°æ®ä¸ºç©º"
    except Exception as e:
        error_msg = f"{type(e).__name__}: {str(e)}"
        print(f"  âœ— è´¢åŠ¡æŠ¥è¡¨è·å–å¤±è´¥: {error_msg}")
        status['statements']['error'] = error_msg
    
    # 3. åˆå¹¶å¯ç”¨çš„æ•°æ®
    print(f"[3/3] åˆå¹¶æ•°æ®...")
    
    if not available_tables:
        print(f"\nâŒ ç¾è‚¡ {stock_code} æ•°æ®è·å–å¤±è´¥ï¼šæ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å–")
        print(f"{'='*60}\n")
        return pd.DataFrame(), status
    
    if len(available_tables) == 1:
        result_df = available_tables[0]
        print(f"  â„¹ï¸  ä»…è·å–åˆ° {status['data_sources'][0]} æ•°æ®")
    else:
        # åˆå¹¶å¤šä¸ªæ•°æ®æº
        result_df = _merge_tables_with_global_rename(available_tables, on='REPORT_DATE')
    
    print(f"\nâœ… ç¾è‚¡ {stock_code} æ•°æ®è·å–å®Œæˆ")
    print(f"   æœ€ç»ˆæ•°æ®ï¼š{len(result_df)} è¡Œ Ã— {len(result_df.columns)} åˆ—")
    print(f"   æ•°æ®æ¥æºï¼š{', '.join(status['data_sources'])}")
    if status['indicator']['error'] or status['statements']['error']:
        print(f"   âš ï¸  éƒ¨åˆ†æ•°æ®è·å–å¤±è´¥ï¼š")
        if status['indicator']['error']:
            print(f"      - è´¢åŠ¡æŒ‡æ ‡: {status['indicator']['error']}")
        if status['statements']['error']:
            print(f"      - è´¢åŠ¡æŠ¥è¡¨: {status['statements']['error']}")
    print(f"{'='*60}\n")
    
    return result_df.sort_values('REPORT_DATE', ascending=False), status


# ==================== å†å²æ•°æ®è·å–å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰====================

def get_historical_data(stock_code, market='A', period='daily', days=365):
    """è·å–è‚¡ç¥¨å†å²æ•°æ®
    
    ä»ä¸œæ–¹è´¢å¯Œç½‘è·å–æŒ‡å®šè‚¡ç¥¨çš„å†å²ä»·æ ¼æ•°æ®ã€‚
    
    Args:
        stock_code (str): è‚¡ç¥¨ä»£ç 
        market (str): å¸‚åœºç±»å‹ã€‚å¯é€‰å€¼ï¼š
            - 'A': Aè‚¡å¸‚åœº
            - 'HK': æ¸¯è‚¡å¸‚åœº
            - 'US': ç¾è‚¡å¸‚åœº
        period (str): æ•°æ®å‘¨æœŸã€‚å¯é€‰å€¼ï¼š
            - 'daily': æ—¥Kçº¿
            - 'weekly': å‘¨Kçº¿
        days (int): è·å–å¤©æ•°ï¼Œé»˜è®¤365å¤©
    
    Returns:
        pd.DataFrame: å†å²æ•°æ®ï¼ŒåŒ…å«æ—¥æœŸã€å¼€ç›˜ä»·ã€æ”¶ç›˜ä»·ã€æœ€é«˜ä»·ã€æœ€ä½ä»·ã€æˆäº¤é‡ç­‰
    """
    current_date = datetime.now()
    start_date = current_date - timedelta(days=days)
    start_date_str = start_date.strftime("%Y%m%d")
    end_date_str = current_date.strftime("%Y%m%d")
    
    if market == 'A':
        return _get_a_historical_data(stock_code, period, start_date_str, end_date_str)
    elif market == 'HK':
        return _get_hk_historical_data(stock_code, period, start_date_str, end_date_str)
    elif market == 'US':
        return _get_us_historical_data(stock_code, period, start_date_str, end_date_str)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„å¸‚åœºç±»å‹: {market}")


def _get_a_historical_data(symbol, period, start_date, end_date):
    """è·å–Aè‚¡å†å²æ•°æ®"""
    return ak.stock_zh_a_hist(symbol=symbol, period=period, start_date=start_date, end_date=end_date, adjust="")


def _get_hk_historical_data(symbol, period, start_date, end_date):
    """è·å–æ¸¯è‚¡å†å²æ•°æ®"""
    return ak.stock_hk_hist(symbol=symbol, period=period, start_date=start_date, end_date=end_date, adjust="")


def _get_us_historical_data(symbol, period, start_date, end_date):
    """è·å–ç¾è‚¡å†å²æ•°æ®"""
    return ak.stock_us_hist(symbol=symbol, period=period, start_date=start_date, end_date=end_date, adjust="")


# ==================== å…¶ä»–è¾…åŠ©å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰====================

def a_dividend_distribution_detail(stock_code):
    """è·å–Aè‚¡åˆ†çº¢é…é€è¯¦æƒ…
    
    Args:
        stock_code (str): Aè‚¡è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ï¼š'000001', '600519', '002594'
    
    Returns:
        pd.DataFrame: åˆ†çº¢é…é€è¯¦æƒ…æ•°æ®æ¡†
    """
    try:
        df = ak.stock_fhps_detail_em(symbol=stock_code)
        
        if not isinstance(df, pd.DataFrame):
            print(f"è·å–Aè‚¡ {stock_code} åˆ†çº¢é…é€è¯¦æƒ…è¿”å›æ•°æ®æ ¼å¼å¼‚å¸¸")
            return pd.DataFrame()
        
        # è½¬æ¢æ—¥æœŸåˆ—ä¸ºå­—ç¬¦ä¸²æ ¼å¼
        date_columns = ['è‚¡æƒç™»è®°æ—¥', 'é™¤æƒé™¤æ¯æ—¥', 'é¢„æ¡ˆå…¬å‘Šæ—¥', 'è‚¡ä¸œå¤§ä¼šé¢„æ¡ˆå…¬å‘Šæ—¥']
        for col in date_columns:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce').dt.strftime('%Y-%m-%d')
        
        return df
        
    except Exception as e:
        print(f"è·å–Aè‚¡ {stock_code} åˆ†çº¢é…é€è¯¦æƒ…å¤±è´¥: {e}")
        return pd.DataFrame()


def a_shareholder_number_detail(stock_code):
    """è·å–Aè‚¡è‚¡ä¸œæˆ·æ•°è¯¦æƒ…
    
    Args:
        stock_code (str): Aè‚¡è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ï¼š'000001', '600519', '002594'
    
    Returns:
        pd.DataFrame: è‚¡ä¸œæˆ·æ•°è¯¦æƒ…æ•°æ®æ¡†
    """
    try:
        df = ak.stock_zh_a_gdhs_detail_em(symbol=stock_code)
        
        if not isinstance(df, pd.DataFrame):
            print(f"è·å–Aè‚¡ {stock_code} è‚¡ä¸œæˆ·æ•°è¯¦æƒ…è¿”å›æ•°æ®æ ¼å¼å¼‚å¸¸")
            return pd.DataFrame()
        
        # è½¬æ¢æ—¥æœŸåˆ—ä¸ºå­—ç¬¦ä¸²æ ¼å¼
        if 'è‚¡ä¸œæˆ·æ•°ç»Ÿè®¡æˆªæ­¢æ—¥' in df.columns:
            df['è‚¡ä¸œæˆ·æ•°ç»Ÿè®¡æˆªæ­¢æ—¥'] = pd.to_datetime(df['è‚¡ä¸œæˆ·æ•°ç»Ÿè®¡æˆªæ­¢æ—¥'], errors='coerce').dt.strftime('%Y-%m-%d')
        
        return df
        
    except Exception as e:
        print(f"è·å–Aè‚¡ {stock_code} è‚¡ä¸œæˆ·æ•°è¯¦æƒ…å¤±è´¥: {e}")
        return pd.DataFrame()


